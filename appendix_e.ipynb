{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ffd2631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sms_spam_collection\\SMSSpamCollection.tsv already exists. Skipping download and extraction.\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_path = \"sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path:Path):\n",
    "    if data_file_path.exists():\n",
    "        print(f'{data_file_path} already exists. Skipping download and extraction.')\n",
    "        return\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        with open(zip_path, 'wb') as out_file:\n",
    "            out_file.write(response.read())\n",
    "\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "\n",
    "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
    "    os.rename(original_file_path, data_file_path)\n",
    "    print(f\"File downloaded and saved as {data_file_path}\")\n",
    "\n",
    "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d584d0e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('sms_spam_collection/SMSSpamCollection.tsv')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "183d8fda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                               Text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(data_file_path, sep='\\t', header=None, names=[\"Label\", \"Text\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c657381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4825, 747)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df['Label'] == 'ham'),sum(df['Label'] == 'spam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a6ea454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "ham     4825\n",
       "spam     747\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76ea3598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(747, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Label']=='spam'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d4ab3e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "0    747\n",
       "1    747\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_balanced_dataset(df:pd.DataFrame):\n",
    "    spam_nums = df[df['Label']=='spam'].shape[0]\n",
    "    ham_subset = df[df['Label']=='ham'].sample(spam_nums, random_state=123)\n",
    "    balanced_df = pd.concat([ham_subset, df[df['Label']=='spam']])\n",
    "    return balanced_df\n",
    "\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\":0,\"spam\":1}) # 将标签映射成0和1\n",
    "balanced_df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "048f8f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4307    0\n",
       "4138    0\n",
       "4831    0\n",
       "4461    0\n",
       "5440    0\n",
       "       ..\n",
       "5537    1\n",
       "5540    1\n",
       "5547    1\n",
       "5566    1\n",
       "5567    1\n",
       "Name: Label, Length: 1494, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 前面经过了抽取，此处的索引还是最开始加载的数据的索引，而不是0,1,2,3...\n",
    "balanced_df['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ce6c088",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_split(df:pd.DataFrame, train_frac, validation_frac):\n",
    "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "    train_end = int(len(df) * train_frac)\n",
    "    validation_end =  train_end + int(len(df) * validation_frac)\n",
    "\n",
    "    train_df = df[:train_end]\n",
    "    validation_df = df[train_end:validation_end]\n",
    "    test_df = df[validation_end:]\n",
    "\n",
    "    return train_df, validation_df, test_df\n",
    "\n",
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
    "train_df.to_csv(\"train.csv\", index=None)\n",
    "validation_df.to_csv(\"validation.csv\", index=None)\n",
    "test_df.to_csv(\"test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37eb29c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding('gpt2')\n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.encoded_texts = [tokenizer.encode(text) for text in self.data['Text']]\n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "            self.encoded_texts = [encoded_text[:max_length] for encoded_text in self.encoded_texts]\n",
    "        # pad\n",
    "        self.encoded_texts = [encoded_text + [pad_token_id] * (self.max_length - len(encoded_text)) for encoded_text in self.encoded_texts]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        label = self.data.iloc[index]['Label']\n",
    "        encoded = self.encoded_texts[index]\n",
    "        return (torch.tensor(encoded, dtype=torch.long), torch.tensor(label, dtype=torch.long))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.encoded_texts)\n",
    "    \n",
    "    def _longest_encoded_length(self):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            if max_length < len(encoded_text):\n",
    "                max_length = len(encoded_text)\n",
    "        return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34cdc5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SpamDataset(csv_file=\"train.csv\", max_length=None, tokenizer=tokenizer)\n",
    "print(train_dataset.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfbdc613",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = SpamDataset(csv_file=\"validation.csv\", max_length=train_dataset.max_length, tokenizer=tokenizer)\n",
    "test_dataset = SpamDataset(csv_file=\"test.csv\", max_length=train_dataset.max_length, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f95db999",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, drop_last=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "693e3063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([   35,  2507,   703,   466,   345,   588,   262,  6940,  2344,    13,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]),\n",
       " tensor(0))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb06e30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch dimensions: torch.Size([8, 120])\n",
      "Label batch dimensions: torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "for input_batch, target_batch in train_loader:\n",
    "    pass\n",
    "print(\"Input batch dimensions:\", input_batch.shape)\n",
    "print(\"Label batch dimensions:\", target_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40d63599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training batch: 130\n",
      "Validation batch: 19\n",
      "Test batch: 38\n"
     ]
    }
   ],
   "source": [
    "print(f'Training batch: {len(train_loader)}')\n",
    "print(f'Validation batch: {len(val_loader)}')\n",
    "print(f'Test batch: {len(test_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77e5a6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257, # Vocabulary size\n",
    "    \"context_length\": 1024, # Context length\n",
    "    \"drop_rate\": 0.0, # Dropout rate\n",
    "    \"qkv_bias\": True # Query-key-value bias\n",
    "}\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "assert train_dataset.max_length <= BASE_CONFIG[\"context_length\"], (\n",
    "    f\"Dataset length {train_dataset.max_length} exceeds model's context \"\n",
    "    f\"length {BASE_CONFIG['context_length']}. Reinitialize data sets with \"\n",
    "    f\"`max_length={BASE_CONFIG['context_length']}`\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ca47be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a4ca534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256, 10])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "pos_embed_layer = nn.Embedding(100, 256)\n",
    "pos_embed_layer(torch.arange(10)).unsqueeze(0).transpose(-2,-1).shape\n",
    "# torch.tensor([1]).unsqueeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa6870c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4146,   -inf,   -inf,   -inf,   -inf],\n",
       "        [0.2121, 0.4498,   -inf,   -inf,   -inf],\n",
       "        [0.0108, 0.7414, 0.0475,   -inf,   -inf],\n",
       "        [0.0396, 0.2796, 0.4882, 0.8477,   -inf],\n",
       "        [0.9495, 0.4145, 0.6140, 0.4895, 0.0454]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(5,5).masked_fill_(torch.triu(torch.ones(5,5),diagonal=1).bool(), -torch.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57ac1294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True,  True,  True],\n",
       "        [False, False,  True,  True],\n",
       "        [False, False, False,  True],\n",
       "        [False, False, False, False]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.triu(torch.ones(5,5),diagonal=1).bool()[:4,:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b218e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 尝试重新手写GPT模型\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, emb_dim, n_heads, qkv_bias, drop_rate, context_length):\n",
    "        super().__init__()\n",
    "        assert emb_dim % n_heads == 0, 'error'\n",
    "        self.emb_dim = emb_dim\n",
    "        self.n_heads = n_heads\n",
    "        self.head_dim = emb_dim // n_heads\n",
    "        self.W_q = nn.Linear(emb_dim, emb_dim, bias=qkv_bias)\n",
    "        self.W_k = nn.Linear(emb_dim, emb_dim, bias=qkv_bias)\n",
    "        self.W_v = nn.Linear(emb_dim, emb_dim, bias=qkv_bias)\n",
    "        self.W_o = nn.Linear(emb_dim, emb_dim, bias=False)\n",
    "        self.droput = nn.Dropout(drop_rate)\n",
    "        # 写错了，不用赋值\n",
    "        #self.mask = self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1).bool())\n",
    "        self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1).bool())\n",
    "\n",
    "    def forward(self, x:torch.Tensor): # shape (B,L,D)\n",
    "        batch, seq_len, dim = x.shape\n",
    "        # 先投影\n",
    "        queries = self.W_q(x)\n",
    "        keys = self.W_k(x)\n",
    "        values = self.W_v(x)\n",
    "        # 拆头\n",
    "        queries = queries.view(batch, seq_len, self.n_heads, self.head_dim)\n",
    "        keys = keys.view(batch, seq_len, self.n_heads, self.head_dim)\n",
    "        values = values.view(batch, seq_len, self.n_heads, self.head_dim)\n",
    "        # 交换位置\n",
    "        queries = queries.transpose(-2, -3) # shape (B,H,L,H_D)\n",
    "        keys = keys.transpose(-2, -3)\n",
    "        values = values.transpose(-2, -3)\n",
    "        # 计算\n",
    "        scores = queries @ keys.transpose(-1,-2) / (keys.shape[-1] ** 0.5)\n",
    "        scores.masked_fill_(self.mask[:seq_len, :seq_len], -torch.inf) # shape (B,H,L,L)\n",
    "        # 这里也写错了，droput的位置错了，应该是对归一化后得到的注意力权重应用dropout，那下面这种写法可以么？\n",
    "        #scores = self.droput(scores)\n",
    "        #attn_weights = torch.softmax(scores) @ values # shape (B,H,L,H_D)\n",
    "        # 改成：\n",
    "        # dropout要在softmax之后做，dropout的目的让模型不要过度的依赖某些特定的位置，而是更多的关注上下文，\n",
    "        # 所以dropout的目的是随机的让某些位置的注意力为0，这样在与Value矩阵相乘计算context_vec的时候会忽略掉那些被dropout掉的位置的信息\n",
    "        # 如果将dropout放在softmax之前，是达不到这个效果的，因为经过dropout后注意力分数变成0的位置，在经过softmax后不再是0.\n",
    "        attn_weights = torch.softmax(scores, dim=-1)\n",
    "        attn_weights = self.droput(attn_weights)\n",
    "        context_vec = attn_weights @ values\n",
    "        context_vec = context_vec.transpose(-2,-3)\n",
    "        context_vec = context_vec.contiguous().view(batch, seq_len, dim)\n",
    "        # 输出\n",
    "        out = self.W_o(context_vec)\n",
    "        return out\n",
    "\n",
    "class FeedLayer(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(emb_dim, emb_dim * 4)\n",
    "        self.lin2 = nn.Linear(emb_dim * 4, emb_dim)\n",
    "        self.act = nn.GELU()\n",
    "\n",
    "    def forward(self, x): # (B,L,D)\n",
    "        x = self.lin1(x)\n",
    "        x = self.act(x)\n",
    "        return self.lin2(x)\n",
    "\n",
    "class TransformerBlk(nn.Module):\n",
    "    def __init__(self, cfg:dict):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.LayerNorm(cfg['emb_dim'])\n",
    "        self.norm2 = nn.LayerNorm(cfg['emb_dim'])\n",
    "        self.attn = MultiHeadAttention(cfg['emb_dim'], cfg['n_heads'], cfg['qkv_bias'], cfg['drop_rate'])\n",
    "        self.feed = FeedLayer(cfg['emb_dim'])\n",
    "        self.dropout = nn.Dropout(cfg['drop_rate'])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 注意力层\n",
    "        residual = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.attn(x)\n",
    "        # 原来写错了: 不是加了残差才dropout的，而是在注意力模块的输出加dropout\n",
    "        #x = x + residual\n",
    "        #x = self.dropout(x) #?\n",
    "        x = self.dropout(x)\n",
    "        x = x + residual\n",
    "\n",
    "        # 前馈层\n",
    "        residual = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.feed(x)\n",
    "        x = self.dropout(x) # 漏了\n",
    "        x = x + residual\n",
    "        return x\n",
    "\n",
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg:dict):\n",
    "        super().__init__()\n",
    "        self.embed_layer = nn.Embedding(cfg['vocab_size'], cfg['emb_dim'])\n",
    "        self.pos_embed_layer = nn.Embedding(cfg['context_length'], cfg['emb_dim'])\n",
    "        self.embed_drop = nn.Dropout(cfg['drop_rate'])\n",
    "        self.trf_blks = nn.Sequential(*[TransformerBlk(cfg) for _ in range(cfg['n_layers'])])\n",
    "        self.final_norm = nn.LayerNorm(cfg['emb_dim']) # 漏了\n",
    "        self.out_head = nn.Linear(cfg['emb_dim'], cfg['vocab_size'])\n",
    "\n",
    "    def forward(self, inputs): # inputs shape:(B,L)\n",
    "        # embeding\n",
    "        length = inputs.shape[1]\n",
    "        embed = self.embed_layer(inputs)\n",
    "        pos_embed = self.pos_embed_layer(torch.arange(length)).unsqueeze(0)\n",
    "        x = embed + pos_embed # shape: (B,L,D)\n",
    "        x = self.embed_drop(x) # 在得到嵌入后应用dropout，思路是：让模型在理解的时候，不依赖特定位置的输入\n",
    "        # attn\n",
    "        x = self.trf_blks(x) # shape:(B,L,D)\n",
    "        x = self.final_norm(x)\n",
    "        # out\n",
    "        x = self.out_head(x)\n",
    "        return x # shape(B,L,V)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "252c3082",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "        self.eps = 1e-5\n",
    "\n",
    "    def forward(self, x:torch.Tensor):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        x_norm = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * x_norm + self.shift\n",
    "    \n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, num_heads, dropout, qkv_bias):\n",
    "        super().__init__()\n",
    "        assert d_out % num_heads == 0, \"d_out must be divisible by num_heads\"\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads\n",
    "        self.W_q = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_k = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_v = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_o = nn.Linear(d_out, d_out)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1).bool())\n",
    "\n",
    "    def forward(self, x:torch.Tensor):\n",
    "        batch, seq_len, dim = x.shape\n",
    "        queries = self.W_q(x).view(batch, seq_len, self.num_heads, self.head_dim)\n",
    "        keys = self.W_k(x).view(batch, seq_len, self.num_heads, self.head_dim)\n",
    "        values = self.W_v(x).view(batch, seq_len, self.num_heads, self.head_dim)\n",
    "\n",
    "        queries = queries.transpose(1, 2)  # (B, num_heads, L, head_dim)\n",
    "        keys = keys.transpose(1, 2)        # (B, num_heads, L, head_dim)\n",
    "        values = values.transpose(1, 2)    # (B, num_heads, L, head_dim)\n",
    "\n",
    "        attn_scores = queries @ keys.transpose(-2, -1) / keys.shape[-1] ** 0.5 # （B, num_heads, L, L）\n",
    "        attn_scores.masked_fill_(self.mask[:seq_len, :seq_len], -torch.inf)\n",
    "        attn_weights = torch.softmax(attn_scores, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        context_vec = attn_weights @ values  # (B, num_heads, L, head_dim)\n",
    "        context_vec = context_vec.transpose(1, 2).contiguous().view(batch, seq_len, dim)  # (B, L, D)\n",
    "        return self.W_o(context_vec)\n",
    "    \n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(torch.sqrt(torch.tensor(2 / torch.pi)) * (x + 0.044715 * torch.pow(x, 3))))\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(emb_dim, 4 * emb_dim)\n",
    "        self.fc2 = nn.Linear(4 * emb_dim, emb_dim)\n",
    "        # self.act = nn.GELU()\n",
    "        self.act = GELU()\n",
    "\n",
    "    def forward(self, x:torch.Tensor):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.norm1 = LayerNorm(cfg['emb_dim'])\n",
    "        self.norm2 = LayerNorm(cfg['emb_dim'])\n",
    "        self.attn = MultiHeadAttention(cfg['emb_dim'], cfg['emb_dim'], cfg['context_length'], cfg['n_heads'], cfg['drop_rate'], cfg['qkv_bias'])\n",
    "        self.ffn = FeedForward(cfg['emb_dim'])\n",
    "        self.dropout = nn.Dropout(cfg['drop_rate'])\n",
    "    \n",
    "    def forward(self, x:torch.Tensor):\n",
    "        # 多头\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.attn(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x + shortcut\n",
    "        # 前馈层\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ffn(x)\n",
    "        x = self.dropout(x)\n",
    "        return x + shortcut\n",
    "\n",
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.token_emb = nn.Embedding(cfg['vocab_size'], cfg['emb_dim'])\n",
    "        self.pos_emb = nn.Embedding(cfg['context_length'], cfg['emb_dim'])\n",
    "        self.drop_emp = nn.Dropout(cfg['drop_rate'])\n",
    "        self.blks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg['n_layers'])]\n",
    "        )\n",
    "        self.final_norm = LayerNorm(cfg['emb_dim'])\n",
    "        self.out_head = nn.Linear(cfg['emb_dim'], cfg['vocab_size'])\n",
    "\n",
    "    def forward(self, in_idx:torch.Tensor):\n",
    "        batch, seq_len = in_idx.shape\n",
    "        token_embeded = self.token_emb(in_idx) # (B,L,D)\n",
    "        pos_embeded = self.pos_emb(torch.arange(seq_len, device=in_idx.device)) # (L,D)\n",
    "        x = token_embeded + pos_embeded  # (B,L,D)\n",
    "        x = self.drop_emp(x) # (B,L,D)\n",
    "        x = self.blks(x) # (B,L,D)\n",
    "        x = self.final_norm(x) # (B,L,D)\n",
    "        logits = self.out_head(x) # (B,L,V)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70eb29be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 5.5 Loading OpenAI weights into our GPT model code\n",
    "import numpy as np\n",
    "\n",
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])               #A\n",
    "    gpt.token_emb.weight = assign(gpt.token_emb.weight, params['wte'])\n",
    "    for b in range(len(params[\"blocks\"])):                                       #B\n",
    "        q_w, k_w, v_w = np.split(                                                #C\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.blks[b].attn.W_q.weight = assign(\n",
    "            gpt.blks[b].attn.W_q.weight, q_w.T)\n",
    "        gpt.blks[b].attn.W_k.weight = assign(\n",
    "            gpt.blks[b].attn.W_k.weight, k_w.T)\n",
    "        gpt.blks[b].attn.W_v.weight = assign(\n",
    "            gpt.blks[b].attn.W_v.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.blks[b].attn.W_q.bias = assign(\n",
    "            gpt.blks[b].attn.W_q.bias, q_b)\n",
    "        gpt.blks[b].attn.W_k.bias = assign(\n",
    "            gpt.blks[b].attn.W_k.bias, k_b)\n",
    "        gpt.blks[b].attn.W_v.bias = assign(\n",
    "            gpt.blks[b].attn.W_v.bias, v_b)\n",
    "\n",
    "        gpt.blks[b].attn.W_o.weight = assign(\n",
    "            gpt.blks[b].attn.W_o.weight,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.blks[b].attn.W_o.bias = assign(\n",
    "            gpt.blks[b].attn.W_o.bias,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.blks[b].ffn.fc1.weight = assign(\n",
    "            gpt.blks[b].ffn.fc1.weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.blks[b].ffn.fc1.bias = assign(\n",
    "            gpt.blks[b].ffn.fc1.bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.blks[b].ffn.fc2.weight = assign(\n",
    "            gpt.blks[b].ffn.fc2.weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.blks[b].ffn.fc2.bias = assign(\n",
    "            gpt.blks[b].ffn.fc2.bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.blks[b].norm1.scale = assign(\n",
    "            gpt.blks[b].norm1.scale,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.blks[b].norm1.shift = assign(\n",
    "            gpt.blks[b].norm1.shift,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.blks[b].norm2.scale = assign(\n",
    "            gpt.blks[b].norm2.scale,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.blks[b].norm2.shift = assign(\n",
    "            gpt.blks[b].norm2.shift,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
    "\n",
    "\n",
    "#A 将模型的位置嵌入和token 嵌入的权重设置为 params 中指定的值\n",
    "#B 遍历模型中的每个 Transformer 模块\n",
    "#C 使用 np.split 函数将注意力和偏置权重分为三等份，分别用于查询、键和值组件\n",
    "#D OpenAI 的原始 GPT-2 模型在输出层中复用了 token 嵌入的权重，以减少参数总量，这一概念称为权重共享\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e7a3e586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124M\n",
      "File already exists and is up-to-date: gpt2\\124M\\checkpoint\n",
      "File already exists and is up-to-date: gpt2\\124M\\encoder.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\hparams.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2\\124M\\vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "print(model_size)\n",
    "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b7ba5bab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (token_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emp): Dropout(p=0.0, inplace=False)\n",
       "  (blks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a24f531e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:] # 取从当前序列的最后context_size个token作为条件输入\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]  # 取最后一个时间步的logits\n",
    "        # probas = torch.softmax(logits, dim=-1)\n",
    "        # idx_next = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "        idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # logits和probas的大小关系是对应的，所以可以直接对logits应用argmax得到词元id\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    return idx\n",
    "\n",
    "import tiktoken\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # 添加batch维度\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)\n",
    "    return tokenizer.decode(flat.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98d8de0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work\n"
     ]
    }
   ],
   "source": [
    "text_1 = \"Every effort moves you\"\n",
    "\n",
    "token_ids = generate_text_simple(model=model, \n",
    "                                 idx=text_to_token_ids(text_1, tokenizer), \n",
    "                                 max_new_tokens=15, \n",
    "                                 context_size=BASE_CONFIG['context_length'])\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c77c5702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (token_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emp): Dropout(p=0.0, inplace=False)\n",
       "  (blks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 分类微调，替换输出层\n",
    "torch.manual_seed(123)\n",
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear(in_features=BASE_CONFIG['emb_dim'], out_features=num_classes)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ace29684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算分类正确率\n",
    "def calc_accuracy_loader(data_loader:DataLoader, model:nn.Module, device:torch.device, num_batches=None):\n",
    "    model.eval()\n",
    "    correct_prediction, num_examples = 0, 0\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for idx, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if idx >= num_batches:\n",
    "            break\n",
    "        input_batch = input_batch.to(device)\n",
    "        target_batch = target_batch.to(device)\n",
    "        with torch.no_grad():\n",
    "            logits = model(input_batch)[:,-1,:] # 取最后一个token\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        num_examples += predictions.shape[0]\n",
    "        correct_prediction += ((predictions == target_batch).sum().item())\n",
    "    return correct_prediction / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8925c6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 46.2500%, Val accuracy: 45.0000%, Test accuracy: 48.7500%\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "print(f\"Train accuracy: {train_accuracy*100:.4f}%, Val accuracy: {val_accuracy*100:.4f}%, Test accuracy: {test_accuracy*100:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d0a9b971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个Lora层\n",
    "import math\n",
    "\n",
    "class LoRALayer(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, rank, alpha):\n",
    "        super().__init__()\n",
    "        self.A = nn.Parameter(torch.empty(in_dim, rank))\n",
    "        nn.init.kaiming_uniform_(self.A, a=math.sqrt(5))\n",
    "        self.B = nn.Parameter(torch.zeros(rank, out_dim)) # 矩阵B初始化为0，这样初始时Lora层的输出为0\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.alpha * (x @ self.A @ self.B)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5d845bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用于替换原始模型的线性层\n",
    "\n",
    "class LinearWithLoRA(nn.Module):\n",
    "    def __init__(self, linear:nn.Linear, rank, alpha):\n",
    "        super().__init__()\n",
    "        self.linear = linear # 原来的线性层\n",
    "        self.lora = LoRALayer(linear.in_features, linear.out_features, rank, alpha)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x) + self.lora(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4070d17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 替换原模型的线性层的工具方法\n",
    "\n",
    "def replace_linear_with_lora(model:nn.Module, rank, alpha):\n",
    "    for name, module in model.named_children():\n",
    "        if isinstance(module, torch.nn.Linear):\n",
    "            setattr(model, name, LinearWithLoRA(module, rank, alpha))\n",
    "        else: # 递归到子模块去\n",
    "            replace_linear_with_lora(module, rank, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2aefd1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_emb\n",
      "pos_emb\n",
      "drop_emp\n",
      "blks\n",
      "final_norm\n",
      "out_head\n"
     ]
    }
   ],
   "source": [
    "for name, module in model.named_children():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1f70d5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters before: 124,441,346\n",
      "Total trainable parameters after:0\n"
     ]
    }
   ],
   "source": [
    "# 先冻结原模型所有参数\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Total trainable parameters before: {total_params:,}')\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "total_params = sum(p for p in model.parameters() if p.requires_grad)\n",
    "print(f'Total trainable parameters after:{total_params:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fa6a2f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable LoRA parameters:2,666,528\n"
     ]
    }
   ],
   "source": [
    "# 接着替换掉原模型中的所有线性层\n",
    "replace_linear_with_lora(model, rank=16, alpha=16)\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Total trainable LoRA parameters:{total_params:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1d625254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (token_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emp): Dropout(p=0.0, inplace=False)\n",
      "  (blks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (attn): MultiHeadAttention(\n",
      "        (W_q): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_k): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_v): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_o): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (fc1): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (fc2): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (act): GELU()\n",
      "      )\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (attn): MultiHeadAttention(\n",
      "        (W_q): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_k): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_v): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_o): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (fc1): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (fc2): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (act): GELU()\n",
      "      )\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (attn): MultiHeadAttention(\n",
      "        (W_q): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_k): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_v): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_o): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (fc1): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (fc2): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (act): GELU()\n",
      "      )\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (attn): MultiHeadAttention(\n",
      "        (W_q): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_k): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_v): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_o): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (fc1): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (fc2): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (act): GELU()\n",
      "      )\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (attn): MultiHeadAttention(\n",
      "        (W_q): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_k): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_v): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_o): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (fc1): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (fc2): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (act): GELU()\n",
      "      )\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (attn): MultiHeadAttention(\n",
      "        (W_q): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_k): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_v): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_o): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (fc1): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (fc2): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (act): GELU()\n",
      "      )\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (attn): MultiHeadAttention(\n",
      "        (W_q): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_k): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_v): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_o): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (fc1): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (fc2): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (act): GELU()\n",
      "      )\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (attn): MultiHeadAttention(\n",
      "        (W_q): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_k): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_v): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_o): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (fc1): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (fc2): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (act): GELU()\n",
      "      )\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (attn): MultiHeadAttention(\n",
      "        (W_q): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_k): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_v): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_o): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (fc1): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (fc2): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (act): GELU()\n",
      "      )\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (attn): MultiHeadAttention(\n",
      "        (W_q): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_k): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_v): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_o): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (fc1): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (fc2): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (act): GELU()\n",
      "      )\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (attn): MultiHeadAttention(\n",
      "        (W_q): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_k): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_v): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_o): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (fc1): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (fc2): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (act): GELU()\n",
      "      )\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (attn): MultiHeadAttention(\n",
      "        (W_q): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_k): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_v): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_o): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (fc1): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (fc2): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (act): GELU()\n",
      "      )\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm()\n",
      "  (out_head): LinearWithLoRA(\n",
      "    (linear): Linear(in_features=768, out_features=2, bias=True)\n",
      "    (lora): LoRALayer()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8aaf393a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:46.25%\n",
      "Validation accuracy:45.00%\n",
      "Test accuracy:48.75%\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f'Training accuracy:{train_accuracy*100:.2f}%')\n",
    "print(f'Validation accuracy:{val_accuracy*100:.2f}%')\n",
    "print(f'Test accuracy:{test_accuracy*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "103631e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch:torch.Tensor, target_batch:torch.Tensor, model:nn.Module, device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    logits = model(input_batch)[:,-1,:]\n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f5ceb328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader:DataLoader, model:nn.Module, device:torch.device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d83051c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model:torch.nn.Module, train_loader:DataLoader, val_loader:DataLoader, device:torch.device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "def train_classifier_simple(model:nn.Module, train_loader:DataLoader, val_loader:DataLoader, optimizer:torch.optim.Optimizer, device:torch.device, num_epochs, eval_freq, eval_iter):\n",
    "    train_losses, val_losses, train_accs, val_accs = [],[],[],[]\n",
    "    example_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            example_seen += input_batch.shape[0]\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                print(f'Ep {epoch+1} (Step {global_step:06d}):Train loss {train_loss:.3f} Val loss {val_loss:.3f}')\n",
    "\n",
    "        # 每轮后算下准确率\n",
    "        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "\n",
    "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
    "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "        \n",
    "    return train_losses, val_losses, train_accs, val_accs, example_seen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bbb3fa76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000):Train loss 3.820 Val loss 3.462\n",
      "Ep 1 (Step 000050):Train loss 0.396 Val loss 0.364\n",
      "Ep 1 (Step 000100):Train loss 0.111 Val loss 0.229\n",
      "Training accuracy: 97.50% | Validation accuracy: 95.00%\n",
      "Ep 2 (Step 000150):Train loss 0.135 Val loss 0.073\n",
      "Ep 2 (Step 000200):Train loss 0.007 Val loss 0.054\n",
      "Ep 2 (Step 000250):Train loss 0.021 Val loss 0.182\n",
      "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
      "Ep 3 (Step 000300):Train loss 0.101 Val loss 0.070\n",
      "Ep 3 (Step 000350):Train loss 0.027 Val loss 0.122\n",
      "Training accuracy: 100.00% | Validation accuracy: 92.50%\n",
      "Ep 4 (Step 000400):Train loss 0.016 Val loss 0.014\n",
      "Ep 4 (Step 000450):Train loss 0.010 Val loss 0.047\n",
      "Ep 4 (Step 000500):Train loss 0.001 Val loss 0.070\n",
      "Training accuracy: 100.00% | Validation accuracy: 95.00%\n",
      "Ep 5 (Step 000550):Train loss 0.001 Val loss 0.189\n",
      "Ep 5 (Step 000600):Train loss 0.022 Val loss 0.146\n",
      "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
      "Training compledt in 0.45 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "torch.manual_seed(123)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 5\n",
    "train_losses, val_losses, train_accs, val_accs, example_seen = train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs=num_epochs, eval_freq=50, eval_iter=5)\n",
    "end_time = time.time()\n",
    "exec_time_min = (end_time - start_time) / 60\n",
    "print(f'Training compledt in {exec_time_min:.2f} min.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ee69ad4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")    #A\n",
    "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2 = ax1.twiny()                                                 #B\n",
    "    ax2.plot(examples_seen, train_values, alpha=0) # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Examples seen\")\n",
    "\n",
    "    fig.tight_layout()                                                #C\n",
    "    plt.savefig(f\"{label}-plot.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9e29e6a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, example_seen, len(train_losses))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses, label=\"loss\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3dbb30a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:100.00%\n",
      "Validation accuracy:100.00%\n",
      "Test accuracy:97.50%\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f'Training accuracy:{train_accuracy*100:.2f}%')\n",
    "print(f'Validation accuracy:{val_accuracy*100:.2f}%')\n",
    "print(f'Test accuracy:{test_accuracy*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b84f4d",
   "metadata": {},
   "source": [
    "尝试下通过LoRA仅微调注意力模块\n",
    "\n",
    "结论：感觉其实差不多，就是相比上面使用LoRA微调全部的liner层要稍微差一点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "96da84dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (token_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emp): Dropout(p=0.0, inplace=False)\n",
       "  (blks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "59c81c86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (token_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emp): Dropout(p=0.0, inplace=False)\n",
       "  (blks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 分类微调，替换输出层\n",
    "torch.manual_seed(123)\n",
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear(in_features=BASE_CONFIG['emb_dim'], out_features=num_classes)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dc26cac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters before: 124,441,346\n",
      "Total trainable parameters after:0\n"
     ]
    }
   ],
   "source": [
    "# 先冻结原模型所有参数\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Total trainable parameters before: {total_params:,}')\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "total_params = sum(p for p in model.parameters() if p.requires_grad)\n",
    "print(f'Total trainable parameters after:{total_params:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1d14785a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_qkv_linear_with_lora(model:nn.Module, rank, alpha):\n",
    "    for name, module in model.named_children():\n",
    "        if isinstance(module, MultiHeadAttention):\n",
    "            # setattr(model, name, LinearWithLoRA(module, rank, alpha))\n",
    "            for name, layer in module.named_children():\n",
    "                if name in ('W_q', 'W_k', 'W_v', 'W_o'):\n",
    "                    # print(name, layer)\n",
    "                    setattr(module, name, LinearWithLoRA(layer, rank, alpha))\n",
    "        else: # 递归到子模块去\n",
    "            replace_qkv_linear_with_lora(module, rank, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ebc6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分类微调，替换输出层\n",
    "torch.manual_seed(123)\n",
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear(in_features=BASE_CONFIG['emb_dim'], out_features=num_classes)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377b101a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (token_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emp): Dropout(p=0.0, inplace=False)\n",
      "  (blks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (attn): MultiHeadAttention(\n",
      "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (act): GELU()\n",
      "      )\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (attn): MultiHeadAttention(\n",
      "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (act): GELU()\n",
      "      )\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (attn): MultiHeadAttention(\n",
      "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (act): GELU()\n",
      "      )\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (attn): MultiHeadAttention(\n",
      "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (act): GELU()\n",
      "      )\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (attn): MultiHeadAttention(\n",
      "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (act): GELU()\n",
      "      )\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (attn): MultiHeadAttention(\n",
      "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (act): GELU()\n",
      "      )\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (attn): MultiHeadAttention(\n",
      "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (act): GELU()\n",
      "      )\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (attn): MultiHeadAttention(\n",
      "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (act): GELU()\n",
      "      )\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (attn): MultiHeadAttention(\n",
      "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (act): GELU()\n",
      "      )\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (attn): MultiHeadAttention(\n",
      "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (act): GELU()\n",
      "      )\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (attn): MultiHeadAttention(\n",
      "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (act): GELU()\n",
      "      )\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (attn): MultiHeadAttention(\n",
      "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (act): GELU()\n",
      "      )\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm()\n",
      "  (out_head): Linear(in_features=768, out_features=50257, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5d7d2876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:46.25%\n",
      "Validation accuracy:45.00%\n",
      "Test accuracy:48.75%\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f'Training accuracy:{train_accuracy*100:.2f}%')\n",
    "print(f'Validation accuracy:{val_accuracy*100:.2f}%')\n",
    "print(f'Test accuracy:{test_accuracy*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4759241d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable LoRA parameters:1,179,648\n"
     ]
    }
   ],
   "source": [
    "# 接着替换掉原模型中的qkv模块\n",
    "replace_qkv_linear_with_lora(model, rank=16, alpha=16)\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Total trainable LoRA parameters:{total_params:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d725c779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (token_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emp): Dropout(p=0.0, inplace=False)\n",
      "  (blks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (attn): MultiHeadAttention(\n",
      "        (W_q): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_k): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_v): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_o): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (act): GELU()\n",
      "      )\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (attn): MultiHeadAttention(\n",
      "        (W_q): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_k): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_v): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_o): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (act): GELU()\n",
      "      )\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (attn): MultiHeadAttention(\n",
      "        (W_q): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_k): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_v): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_o): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (act): GELU()\n",
      "      )\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (attn): MultiHeadAttention(\n",
      "        (W_q): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_k): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_v): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_o): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (act): GELU()\n",
      "      )\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (attn): MultiHeadAttention(\n",
      "        (W_q): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_k): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_v): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_o): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (act): GELU()\n",
      "      )\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (attn): MultiHeadAttention(\n",
      "        (W_q): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_k): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_v): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_o): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (act): GELU()\n",
      "      )\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (attn): MultiHeadAttention(\n",
      "        (W_q): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_k): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_v): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_o): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (act): GELU()\n",
      "      )\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (attn): MultiHeadAttention(\n",
      "        (W_q): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_k): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_v): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_o): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (act): GELU()\n",
      "      )\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (attn): MultiHeadAttention(\n",
      "        (W_q): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_k): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_v): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_o): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (act): GELU()\n",
      "      )\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (attn): MultiHeadAttention(\n",
      "        (W_q): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_k): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_v): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_o): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (act): GELU()\n",
      "      )\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (attn): MultiHeadAttention(\n",
      "        (W_q): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_k): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_v): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_o): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (act): GELU()\n",
      "      )\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (attn): MultiHeadAttention(\n",
      "        (W_q): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_k): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_v): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_o): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (act): GELU()\n",
      "      )\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm()\n",
      "  (out_head): Linear(in_features=768, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e9942ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:46.25%\n",
      "Validation accuracy:45.00%\n",
      "Test accuracy:48.75%\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f'Training accuracy:{train_accuracy*100:.2f}%')\n",
    "print(f'Validation accuracy:{val_accuracy*100:.2f}%')\n",
    "print(f'Test accuracy:{test_accuracy*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "59cee94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000):Train loss 2.330 Val loss 2.069\n",
      "Ep 1 (Step 000050):Train loss 0.432 Val loss 0.386\n",
      "Ep 1 (Step 000100):Train loss 0.179 Val loss 0.393\n",
      "Training accuracy: 92.50% | Validation accuracy: 95.00%\n",
      "Ep 2 (Step 000150):Train loss 0.166 Val loss 0.074\n",
      "Ep 2 (Step 000200):Train loss 0.046 Val loss 0.050\n",
      "Ep 2 (Step 000250):Train loss 0.079 Val loss 0.050\n",
      "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
      "Ep 3 (Step 000300):Train loss 0.014 Val loss 0.170\n",
      "Ep 3 (Step 000350):Train loss 0.011 Val loss 0.142\n",
      "Training accuracy: 100.00% | Validation accuracy: 95.00%\n",
      "Ep 4 (Step 000400):Train loss 0.006 Val loss 0.151\n",
      "Ep 4 (Step 000450):Train loss 0.026 Val loss 0.207\n",
      "Ep 4 (Step 000500):Train loss 0.022 Val loss 0.015\n",
      "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
      "Ep 5 (Step 000550):Train loss 0.067 Val loss 0.007\n",
      "Ep 5 (Step 000600):Train loss 0.002 Val loss 0.062\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Training compledt in 0.39 min.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "torch.manual_seed(123)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 5\n",
    "train_losses, val_losses, train_accs, val_accs, example_seen = train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs=num_epochs, eval_freq=50, eval_iter=5)\n",
    "end_time = time.time()\n",
    "exec_time_min = (end_time - start_time) / 60\n",
    "print(f'Training compledt in {exec_time_min:.2f} min.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fc912c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, example_seen, len(train_losses))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses, label=\"loss\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8984eb03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:98.75%\n",
      "Validation accuracy:98.75%\n",
      "Test accuracy:96.25%\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f'Training accuracy:{train_accuracy*100:.2f}%')\n",
    "print(f'Validation accuracy:{val_accuracy*100:.2f}%')\n",
    "print(f'Test accuracy:{test_accuracy*100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
