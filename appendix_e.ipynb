{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8ffd2631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sms_spam_collection\\SMSSpamCollection.tsv already exists. Skipping download and extraction.\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_path = \"sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path:Path):\n",
    "    if data_file_path.exists():\n",
    "        print(f'{data_file_path} already exists. Skipping download and extraction.')\n",
    "        return\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        with open(zip_path, 'wb') as out_file:\n",
    "            out_file.write(response.read())\n",
    "\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "\n",
    "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
    "    os.rename(original_file_path, data_file_path)\n",
    "    print(f\"File downloaded and saved as {data_file_path}\")\n",
    "\n",
    "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d584d0e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('sms_spam_collection/SMSSpamCollection.tsv')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "183d8fda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                               Text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(data_file_path, sep='\\t', header=None, names=[\"Label\", \"Text\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5c657381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4825, 747)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df['Label'] == 'ham'),sum(df['Label'] == 'spam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2a6ea454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "ham     4825\n",
       "spam     747\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "76ea3598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(747, 2)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Label']=='spam'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5d4ab3e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "0    747\n",
       "1    747\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_balanced_dataset(df:pd.DataFrame):\n",
    "    spam_nums = df[df['Label']=='spam'].shape[0]\n",
    "    ham_subset = df[df['Label']=='ham'].sample(spam_nums, random_state=123)\n",
    "    balanced_df = pd.concat([ham_subset, df[df['Label']=='spam']])\n",
    "    return balanced_df\n",
    "\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\":0,\"spam\":1}) # 将标签映射成0和1\n",
    "balanced_df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "048f8f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4307    0\n",
       "4138    0\n",
       "4831    0\n",
       "4461    0\n",
       "5440    0\n",
       "       ..\n",
       "5537    1\n",
       "5540    1\n",
       "5547    1\n",
       "5566    1\n",
       "5567    1\n",
       "Name: Label, Length: 1494, dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 前面经过了抽取，此处的索引还是最开始加载的数据的索引，而不是0,1,2,3...\n",
    "balanced_df['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1ce6c088",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_split(df:pd.DataFrame, train_frac, validation_frac):\n",
    "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "    train_end = int(len(df) * train_frac)\n",
    "    validation_end =  train_end + int(len(df) * validation_frac)\n",
    "\n",
    "    train_df = df[:train_end]\n",
    "    validation_df = df[train_end:validation_end]\n",
    "    test_df = df[validation_end:]\n",
    "\n",
    "    return train_df, validation_df, test_df\n",
    "\n",
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
    "train_df.to_csv(\"train.csv\", index=None)\n",
    "validation_df.to_csv(\"validation.csv\", index=None)\n",
    "test_df.to_csv(\"test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "37eb29c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding('gpt2')\n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.encoded_texts = [tokenizer.encode(text) for text in self.data['Text']]\n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "            self.encoded_texts = [encoded_text[:max_length] for encoded_text in self.encoded_texts]\n",
    "        # pad\n",
    "        self.encoded_texts = [encoded_text + [pad_token_id] * (self.max_length - len(encoded_text)) for encoded_text in self.encoded_texts]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        label = self.data.iloc[index]['Label']\n",
    "        encoded = self.encoded_texts[index]\n",
    "        return (torch.tensor(encoded, dtype=torch.long), torch.tensor(label, dtype=torch.long))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.encoded_texts)\n",
    "    \n",
    "    def _longest_encoded_length(self):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            if max_length < len(encoded_text):\n",
    "                max_length = len(encoded_text)\n",
    "        return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "34cdc5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SpamDataset(csv_file=\"train.csv\", max_length=None, tokenizer=tokenizer)\n",
    "print(train_dataset.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "cfbdc613",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = SpamDataset(csv_file=\"validation.csv\", max_length=train_dataset.max_length, tokenizer=tokenizer)\n",
    "test_dataset = SpamDataset(csv_file=\"test.csv\", max_length=train_dataset.max_length, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f95db999",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, drop_last=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "693e3063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([   35,  2507,   703,   466,   345,   588,   262,  6940,  2344,    13,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]),\n",
       " tensor(0))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "bb06e30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch dimensions: torch.Size([8, 120])\n",
      "Label batch dimensions: torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "for input_batch, target_batch in train_loader:\n",
    "    pass\n",
    "print(\"Input batch dimensions:\", input_batch.shape)\n",
    "print(\"Label batch dimensions:\", target_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "40d63599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training batch: 130\n",
      "Validation batch: 19\n",
      "Test batch: 38\n"
     ]
    }
   ],
   "source": [
    "print(f'Training batch: {len(train_loader)}')\n",
    "print(f'Validation batch: {len(val_loader)}')\n",
    "print(f'Test batch: {len(test_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "77e5a6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257, # Vocabulary size\n",
    "    \"context_length\": 1024, # Context length\n",
    "    \"drop_rate\": 0.0, # Dropout rate\n",
    "    \"qkv_bias\": True # Query-key-value bias\n",
    "}\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "assert train_dataset.max_length <= BASE_CONFIG[\"context_length\"], (\n",
    "    f\"Dataset length {train_dataset.max_length} exceeds model's context \"\n",
    "    f\"length {BASE_CONFIG['context_length']}. Reinitialize data sets with \"\n",
    "    f\"`max_length={BASE_CONFIG['context_length']}`\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6ca47be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5a4ca534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256, 10])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "pos_embed_layer = nn.Embedding(100, 256)\n",
    "pos_embed_layer(torch.arange(10)).unsqueeze(0).transpose(-2,-1).shape\n",
    "# torch.tensor([1]).unsqueeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "aa6870c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8486,   -inf,   -inf,   -inf,   -inf],\n",
       "        [0.5940, 0.2000,   -inf,   -inf,   -inf],\n",
       "        [0.1176, 0.6319, 0.3527,   -inf,   -inf],\n",
       "        [0.9003, 0.8077, 0.3576, 0.3578,   -inf],\n",
       "        [0.9110, 0.7447, 0.8595, 0.4132, 0.9939]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(5,5).masked_fill_(torch.triu(torch.ones(5,5),diagonal=1).bool(), -torch.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "57ac1294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True,  True,  True],\n",
       "        [False, False,  True,  True],\n",
       "        [False, False, False,  True],\n",
       "        [False, False, False, False]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.triu(torch.ones(5,5),diagonal=1).bool()[:4,:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b218e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 尝试重新手写GPT模型\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, emb_dim, n_heads, qkv_bias, drop_rate, context_length):\n",
    "        super().__init__()\n",
    "        assert emb_dim % n_heads == 0, 'error'\n",
    "        self.emb_dim = emb_dim\n",
    "        self.n_heads = n_heads\n",
    "        self.head_dim = emb_dim // n_heads\n",
    "        self.W_q = nn.Linear(emb_dim, emb_dim, bias=qkv_bias)\n",
    "        self.W_k = nn.Linear(emb_dim, emb_dim, bias=qkv_bias)\n",
    "        self.W_v = nn.Linear(emb_dim, emb_dim, bias=qkv_bias)\n",
    "        self.W_o = nn.Linear(emb_dim, emb_dim, bias=False)\n",
    "        self.droput = nn.Dropout(drop_rate)\n",
    "        # 写错了，不用赋值\n",
    "        #self.mask = self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1).bool())\n",
    "        self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1).bool())\n",
    "\n",
    "    def forward(self, x:torch.Tensor): # shape (B,L,D)\n",
    "        batch, seq_len, dim = x.shape\n",
    "        # 先投影\n",
    "        queries = self.W_q(x)\n",
    "        keys = self.W_k(x)\n",
    "        values = self.W_v(x)\n",
    "        # 拆头\n",
    "        queries = queries.view(batch, seq_len, self.n_heads, self.head_dim)\n",
    "        keys = keys.view(batch, seq_len, self.n_heads, self.head_dim)\n",
    "        values = values.view(batch, seq_len, self.n_heads, self.head_dim)\n",
    "        # 交换位置\n",
    "        queries = queries.transpose(-2, -3) # shape (B,H,L,H_D)\n",
    "        keys = keys.transpose(-2, -3)\n",
    "        values = values.transpose(-2, -3)\n",
    "        # 计算\n",
    "        scores = queries @ keys.transpose(-1,-2) / (keys.shape[-1] ** 0.5)\n",
    "        scores.masked_fill_(self.mask[:seq_len, :seq_len], -torch.inf) # shape (B,H,L,L)\n",
    "        # 这里也写错了，droput的位置错了，应该是对归一化后得到的注意力权重应用dropout，那下面这种写法可以么？\n",
    "        #scores = self.droput(scores)\n",
    "        #attn_weights = torch.softmax(scores) @ values # shape (B,H,L,H_D)\n",
    "        # 改成：\n",
    "        # dropout要在softmax之后做，dropout的目的让模型不要过度的依赖某些特定的位置，而是更多的关注上下文，\n",
    "        # 所以dropout的目的是随机的让某些位置的注意力为0，这样在与Value矩阵相乘计算context_vec的时候会忽略掉那些被dropout掉的位置的信息\n",
    "        # 如果将dropout放在softmax之前，是达不到这个效果的，因为经过dropout后注意力分数变成0的位置，在经过softmax后不再是0.\n",
    "        attn_weights = torch.softmax(scores, dim=-1)\n",
    "        attn_weights = self.droput(attn_weights)\n",
    "        context_vec = attn_weights @ values\n",
    "        context_vec = context_vec.transpose(-2,-3)\n",
    "        context_vec = context_vec.contiguous().view(batch, seq_len, dim)\n",
    "        # 输出\n",
    "        out = self.W_o(context_vec)\n",
    "        return out\n",
    "\n",
    "class FeedLayer(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(emb_dim, emb_dim * 4)\n",
    "        self.lin2 = nn.Linear(emb_dim * 4, emb_dim)\n",
    "        self.act = nn.GELU()\n",
    "\n",
    "    def forward(self, x): # (B,L,D)\n",
    "        x = self.lin1(x)\n",
    "        x = self.act(x)\n",
    "        return self.lin2(x)\n",
    "\n",
    "class TransformerBlk(nn.Module):\n",
    "    def __init__(self, cfg:dict):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.LayerNorm(cfg['emb_dim'])\n",
    "        self.norm2 = nn.LayerNorm(cfg['emb_dim'])\n",
    "        self.attn = MultiHeadAttention(cfg['emb_dim'], cfg['n_heads'], cfg['qkv_bias'], cfg['drop_rate'])\n",
    "        self.feed = FeedLayer(cfg['emb_dim'])\n",
    "        self.dropout = nn.Dropout(cfg['drop_rate'])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 注意力层\n",
    "        residual = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.attn(x)\n",
    "        # 原来写错了: 不是加了残差才dropout的，而是在注意力模块的输出加dropout\n",
    "        #x = x + residual\n",
    "        #x = self.dropout(x) #?\n",
    "        x = self.dropout(x)\n",
    "        x = x + residual\n",
    "\n",
    "        # 前馈层\n",
    "        residual = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.feed(x)\n",
    "        x = self.dropout(x) # 漏了\n",
    "        x = x + residual\n",
    "        return x\n",
    "\n",
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg:dict):\n",
    "        super().__init__()\n",
    "        self.embed_layer = nn.Embedding(cfg['vocab_size'], cfg['emb_dim'])\n",
    "        self.pos_embed_layer = nn.Embedding(cfg['context_length'], cfg['emb_dim'])\n",
    "        self.embed_drop = nn.Dropout(cfg['drop_rate'])\n",
    "        self.trf_blks = nn.Sequential(*[TransformerBlk(cfg) for _ in range(cfg['n_layers'])])\n",
    "        self.final_norm = nn.LayerNorm(cfg['emb_dim']) # 漏了\n",
    "        self.out_head = nn.Linear(cfg['emb_dim'], cfg['vocab_size'])\n",
    "\n",
    "    def forward(self, inputs): # inputs shape:(B,L)\n",
    "        # embeding\n",
    "        length = inputs.shape[1]\n",
    "        embed = self.embed_layer(inputs)\n",
    "        pos_embed = self.pos_embed_layer(torch.arange(length)).unsqueeze(0)\n",
    "        x = embed + pos_embed # shape: (B,L,D)\n",
    "        x = self.embed_drop(x) # 在得到嵌入后应用dropout，思路是：让模型在理解的时候，不依赖特定位置的输入\n",
    "        # attn\n",
    "        x = self.trf_blks(x) # shape:(B,L,D)\n",
    "        x = self.final_norm(x)\n",
    "        # out\n",
    "        x = self.out_head(x)\n",
    "        return x # shape(B,L,V)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
