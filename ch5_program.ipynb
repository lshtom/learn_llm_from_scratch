{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51fd7952",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e21528d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    'vocab_size': 50257,\n",
    "    'context_length': 256,\n",
    "    'emb_dim': 768,\n",
    "    'n_heads': 12,\n",
    "    'n_layers': 12,\n",
    "    'drop_rate': 0.1,\n",
    "    'qkv_bias': False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f664947c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "        self.eps = 1e-5\n",
    "\n",
    "    def forward(self, x:torch.Tensor):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        x_norm = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * x_norm + self.shift\n",
    "    \n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, num_heads, dropout, qkv_bias):\n",
    "        super().__init__()\n",
    "        assert d_out % num_heads == 0, \"d_out must be divisible by num_heads\"\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads\n",
    "        self.W_q = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_k = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_v = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_o = nn.Linear(d_out, d_out)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1).bool())\n",
    "\n",
    "    def forward(self, x:torch.Tensor):\n",
    "        batch, seq_len, dim = x.shape\n",
    "        queries = self.W_q(x).view(batch, seq_len, self.num_heads, self.head_dim)\n",
    "        keys = self.W_k(x).view(batch, seq_len, self.num_heads, self.head_dim)\n",
    "        values = self.W_v(x).view(batch, seq_len, self.num_heads, self.head_dim)\n",
    "\n",
    "        queries = queries.transpose(1, 2)  # (B, num_heads, L, head_dim)\n",
    "        keys = keys.transpose(1, 2)        # (B, num_heads, L, head_dim)\n",
    "        values = values.transpose(1, 2)    # (B, num_heads, L, head_dim)\n",
    "\n",
    "        attn_scores = queries @ keys.transpose(-2, -1) / keys.shape[-1] ** 0.5 # （B, num_heads, L, L）\n",
    "        attn_scores.masked_fill_(self.mask[:seq_len, :seq_len], -torch.inf)\n",
    "        attn_weights = torch.softmax(attn_scores, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        context_vec = attn_weights @ values  # (B, num_heads, L, head_dim)\n",
    "        context_vec = context_vec.transpose(1, 2).contiguous().view(batch, seq_len, dim)  # (B, L, D)\n",
    "        return self.W_o(context_vec)\n",
    "    \n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(torch.sqrt(torch.tensor(2 / torch.pi)) * (x + 0.044715 * torch.pow(x, 3))))\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(emb_dim, 4 * emb_dim)\n",
    "        self.fc2 = nn.Linear(4 * emb_dim, emb_dim)\n",
    "        # self.act = nn.GELU()\n",
    "        self.act = GELU()\n",
    "\n",
    "    def forward(self, x:torch.Tensor):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.norm1 = LayerNorm(cfg['emb_dim'])\n",
    "        self.norm2 = LayerNorm(cfg['emb_dim'])\n",
    "        self.attn = MultiHeadAttention(cfg['emb_dim'], cfg['emb_dim'], cfg['context_length'], cfg['n_heads'], cfg['drop_rate'], cfg['qkv_bias'])\n",
    "        self.ffn = FeedForward(cfg['emb_dim'])\n",
    "        self.dropout = nn.Dropout(cfg['drop_rate'])\n",
    "    \n",
    "    def forward(self, x:torch.Tensor):\n",
    "        # 多头\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.attn(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x + shortcut\n",
    "        # 前馈层\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ffn(x)\n",
    "        x = self.dropout(x)\n",
    "        return x + shortcut\n",
    "\n",
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.token_emb = nn.Embedding(cfg['vocab_size'], cfg['emb_dim'])\n",
    "        self.pos_emb = nn.Embedding(cfg['context_length'], cfg['emb_dim'])\n",
    "        self.drop_emp = nn.Dropout(cfg['drop_rate'])\n",
    "        self.blks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg['n_layers'])]\n",
    "        )\n",
    "        self.final_norm = LayerNorm(cfg['emb_dim'])\n",
    "        self.out_head = nn.Linear(cfg['emb_dim'], cfg['vocab_size'])\n",
    "\n",
    "    def forward(self, in_idx:torch.Tensor):\n",
    "        batch, seq_len = in_idx.shape\n",
    "        token_embeded = self.token_emb(in_idx) # (B,L,D)\n",
    "        pos_embeded = self.pos_emb(torch.arange(seq_len, device=in_idx.device)) # (L,D)\n",
    "        x = token_embeded + pos_embeded  # (B,L,D)\n",
    "        x = self.drop_emp(x) # (B,L,D)\n",
    "        x = self.blks(x) # (B,L,D)\n",
    "        x = self.final_norm(x) # (B,L,D)\n",
    "        logits = self.out_head(x) # (B,L,V)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9354e972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (token_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emp): Dropout(p=0.1, inplace=False)\n",
       "  (blks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1b9248c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:] # 取从当前序列的最后context_size个token作为条件输入\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]  # 取最后一个时间步的logits\n",
    "        # probas = torch.softmax(logits, dim=-1)\n",
    "        # idx_next = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "        idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # logits和probas的大小关系是对应的，所以可以直接对logits应用argmax得到词元id\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a554b287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded: [15496, 11, 314, 716]\n",
      "encoded_tensor shape: torch.Size([1, 4])\n",
      "Output: tensor([[15496,    11,   314,   716, 13240, 11381,  4307,  7640, 16620, 34991]])\n",
      "Output length: 10\n",
      "Decoded text: Hello, I am Laur inhab DistrinetalkQueue\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "start_context = \"Hello, I am\"\n",
    "encoded = tokenizer.encode(start_context)\n",
    "print(\"encoded:\", encoded)\n",
    "encoded_tensor = torch.tensor(encoded).unsqueeze(0)  # 添加batch维度\n",
    "print(\"encoded_tensor shape:\", encoded_tensor.shape)\n",
    "\n",
    "model.eval()\n",
    "out = generate_text_simple(model=model, idx=encoded_tensor, max_new_tokens=6, context_size=GPT_CONFIG_124M['context_length'])\n",
    "print(\"Output:\", out)\n",
    "print(\"Output length:\", len(out[0]))\n",
    "\n",
    "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
    "print(\"Decoded text:\", decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6baf80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic chief refusing holidays Shannon GamergateHay men methamphetamine\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # 添加batch维度\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding('gpt2')\n",
    "\n",
    "token_ids = generate_text_simple(model=model, idx=text_to_token_ids(start_context, tokenizer), max_new_tokens=10, context_size=GPT_CONFIG_124M['context_length'])\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a9ccbfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16833, 3626, 6100]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1 = tokenizer.encode('every effort moves')\n",
    "input1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65528f1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[16833,  3626,  6100,   345],\n",
       "        [   40,  1107,   588, 11311]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_lst = ['every effort moves you', 'I really like chocolate']\n",
    "token_ids = torch.tensor([tokenizer.encode(text) for text in text_lst])\n",
    "token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb478f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[16833,  3626,  6100],\n",
       "        [   40,  1107,   588]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = token_ids[:,:3]\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5fde1d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3626,  6100,   345],\n",
       "        [ 1107,   588, 11311]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = token_ids[:,1:]\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ecef463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids[0].flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8717fd66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n",
      "Token Id:\n",
      " tensor([[[50153],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n",
      "Targets batch 1: effort moves you\n",
      "Output batch 1: PRESIDENT heNetflix\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "print(probas.shape)\n",
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print('Token Id:\\n', token_ids)\n",
    "print(f'Targets batch 1:{token_ids_to_text(targets[0], tokenizer)}')\n",
    "print(f'Output batch 1:{token_ids_to_text(token_ids[0].flatten(), tokenizer)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7710a58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8d8f290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 50257])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "163ebcb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.7791)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "loss(logits.flatten(0,1), targets.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ca1e7d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.7791)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(logits.permute(0,2,1), targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09ad4ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 50257])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.flatten(0,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8b15572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13913c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.7791)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.functional.cross_entropy(logits.flatten(0,1), targets.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5be386f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.7791)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.cross_entropy(logits.permute(0,2,1), targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4cd95fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'the-verdict.txt'\n",
    "with  open(file_path, 'r', encoding='utf-8') as file:\n",
    "    text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32bb6de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print('Characters:', total_characters)\n",
    "print('Tokens:', total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e70b5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3bcfd2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "arr = [1,2,3,4,5,6,7,8,9,10]\n",
    "for idx in range(0,len(arr),2):\n",
    "    print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7429d85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        token_ids = tokenizer.encode(txt)\n",
    "        for idx in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[idx:idx+max_length]\n",
    "            target_chunk = token_ids[idx+1:idx+1+max_length]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.input_ids[index], self.target_ids[index]\n",
    "    \n",
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
    "    tokenizer = tiktoken.get_encoding('gpt2')\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "    return DataLoader(dataset, batch_size, shuffle=shuffle, drop_last=drop_last, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3aedecab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = create_dataloader_v1(train_data, batch_size=2, max_length=GPT_CONFIG_124M['context_length'], stride=GPT_CONFIG_124M['context_length'], drop_last=True, shuffle=True, num_workers=0)\n",
    "val_loader = create_dataloader_v1(val_data, batch_size=2, max_length=GPT_CONFIG_124M['context_length'], stride=GPT_CONFIG_124M['context_length'], drop_last=False, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1670f2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print('Train loader:')\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print('\\nValidation loader:')\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7979671e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader),len(val_loader) # 显示有几个批次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db8ac6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch:torch.Tensor, target_batch:torch.Tensor, model:nn.Module, device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.permute(0,2,1), target_batch)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bbf18f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches: # 这个是为了兼容指定的num_batches小于data_loader的总batch数的情况\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5bcccad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.990696483188206\n",
      "Validation loss: 10.985530853271484\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "print('Training loss:', train_loss)\n",
    "print('Validation loss:', val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "968c4391",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_mode(model:nn.Module, train_loader:DataLoader, val_loader:DataLoader, device:torch.device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "def generate_and_print_sample(model:nn.Module, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(model, encoded, max_new_tokens=50, context_size=context_size)\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace('\\n',''))\n",
    "    model.train()\n",
    "\n",
    "def train_model_simple(model:nn.Module, train_loader:DataLoader, val_loader:DataLoader, optimizer:torch.optim.Optimizer, deivce:torch.device, num_epochs, eval_freq, eval_iter, start_context, tokenizer):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_mode(model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d})：Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # 每轮之后打印一个文本样本\n",
    "        generate_and_print_sample(model, tokenizer, device, start_context)\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ac130ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000)：Train loss 9.810, Val loss 9.967\n",
      "Ep 1 (Step 000005)：Train loss 7.849, Val loss 8.288\n",
      "Every effort moves you the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "Ep 2 (Step 000010)：Train loss 6.691, Val loss 7.055\n",
      "Ep 2 (Step 000015)：Train loss 6.102, Val loss 6.601\n",
      "Every effort moves you.\n",
      "Ep 3 (Step 000020)：Train loss 5.808, Val loss 6.795\n",
      "Ep 3 (Step 000025)：Train loss 5.005, Val loss 6.321\n",
      "Every effort moves you.\"I\"II, and he was aI that.\"I was his pictures--and, and he was, and I had been the fact, and my to the fact, and he was the fact, and I had\n",
      "Ep 4 (Step 000030)：Train loss 4.178, Val loss 6.281\n",
      "Ep 4 (Step 000035)：Train loss 3.647, Val loss 6.273\n",
      "Every effort moves you know the\n",
      "Ep 5 (Step 000040)：Train loss 3.475, Val loss 6.253\n",
      "Every effort moves you know to see on a little of--I to the fact with that, I had been--and I had been.\"I, and down the room, I had\n",
      "Ep 6 (Step 000045)：Train loss 2.934, Val loss 6.183\n",
      "Ep 6 (Step 000050)：Train loss 2.338, Val loss 6.235\n",
      "Every effort moves you know,\" was not that my hostess was \"interesting\": on that I was not that he had been--and here are the cigars you like.\"He placed them at my elbow and I had the fact, and it.\"I\n",
      "Ep 7 (Step 000055)：Train loss 1.871, Val loss 6.227\n",
      "Ep 7 (Step 000060)：Train loss 1.492, Val loss 6.243\n",
      "Every effort moves you know,\" was one of the picture.\"I turned back to my work, and in fact, and. It was just because she was _not_ interesting--and I may be pardoned the bull--that I found\n",
      "Ep 8 (Step 000065)：Train loss 1.119, Val loss 6.353\n",
      "Ep 8 (Step 000070)：Train loss 0.789, Val loss 6.323\n",
      "Every effort moves you?\"\"Yes--quite insensible to the fact with equanimity.He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 9 (Step 000075)：Train loss 0.524, Val loss 6.438\n",
      "Ep 9 (Step 000080)：Train loss 0.434, Val loss 6.500\n",
      "Every effort moves you?\"\"Yes--quite insensible to the fact with equanimity. Poor Jack Gisburn! The women had made him--it was fitting that they should mourn him. Among his own sex fewer regrets were heard, and in his\n",
      "Ep 10 (Step 000085)：Train loss 0.305, Val loss 6.548\n",
      "Every effort moves you?\"I glanced after him, struck by his last word. Victor Grindle was, in fact, becoming the man of the moment--as Jack himself, one might put it, had been the man of the hour. The\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq=5, eval_iter=5, start_context='Every effort moves you', tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9dd7a451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[512,\n",
       " 3072,\n",
       " 5632,\n",
       " 8192,\n",
       " 10752,\n",
       " 13312,\n",
       " 15872,\n",
       " 18432,\n",
       " 20992,\n",
       " 23552,\n",
       " 26112,\n",
       " 28672,\n",
       " 31232,\n",
       " 33792,\n",
       " 36352,\n",
       " 38912,\n",
       " 41472,\n",
       " 44032]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "14a51e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5,3))\n",
    "    ax1.plot(epochs_seen, train_losses, label='Traning loss')\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label='Validation loss')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)\n",
    "    ax2.set_xlabel('Tokens seen')\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "be911eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no great surprise to me to hear that, in the height of his glory, he had dropped his painting, married a rich widow, and established himself in a villa on the\n"
     ]
    }
   ],
   "source": [
    "start_context = 'I HAD always thought Jack Gisburn'\n",
    "generate_and_print_sample(model, tokenizer, device, start_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e2a2afad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_token_logits = torch.tensor([4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79])\n",
    "next_token_id = torch.argmax(next_token_logits)\n",
    "next_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1d3a7ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_token_logits = torch.tensor([4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79])\n",
    "probas = torch.softmax(next_token_logits, dim=-1)\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "next_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "06d34d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 x 0\n",
      "2 x 1\n",
      "0 x 2\n",
      "544 x 3\n",
      "2 x 4\n",
      "1 x 5\n",
      "0 x 6\n",
      "376 x 7\n",
      "4 x 8\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123)\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1000)]\n",
    "    sample_ids = torch.bincount(torch.tensor(sample))\n",
    "    for i, freq in enumerate(sample_ids):\n",
    "        print(f'{freq} x {i}')\n",
    "\n",
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b6af41be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bfad47fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158 x 0\n",
      "20 x 1\n",
      "12 x 2\n",
      "391 x 3\n",
      "37 x 4\n",
      "5 x 5\n",
      "4 x 6\n",
      "340 x 7\n",
      "33 x 8\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens_v2(logits):\n",
    "    torch.manual_seed(123)\n",
    "    sample = [torch.multinomial(softmax_with_temperature(logits, 2), num_samples=1).item() for i in range(1000)]\n",
    "    sample_ids = torch.bincount(torch.tensor(sample))\n",
    "    for i, freq in enumerate(sample_ids):\n",
    "        print(f'{freq} x {i}')\n",
    "\n",
    "print_sampled_tokens_v2(next_token_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "987421ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
      "Top positions: tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "top_k = 3\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "print('Top logits:', top_logits)\n",
    "print('Top positions:', top_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "76049a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False,  True,  True, False,  True,  True,  True, False,  True])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_token_logits < top_logits[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "06ee697e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "new_logits = torch.where(\n",
    "    condition=next_token_logits < top_logits[-1],\n",
    "    input=torch.tensor(float('-inf')),\n",
    "    other=next_token_logits\n",
    ")\n",
    "print(new_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f8c570a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model:nn.Module, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:,-context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:,-1,:] # 取最后一个词\n",
    "        if top_k is not None:\n",
    "            top_logits,_ = torch.topk(logits, top_k)\n",
    "            logits = torch.where(\n",
    "                condition=logits < top_logits[:,-1],\n",
    "                input=torch.tensor(float(\"-inf\")).to(logits.device),\n",
    "                other=logits\n",
    "            )\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probas = torch.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probas, num_samples=1)\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "        if idx_next == eos_id:\n",
    "            break\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "00b06e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was when\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "token_ids = generate(model=model, idx=text_to_token_ids(\"I HAD always thought Jack Gisburn\", tokenizer).to(device), max_new_tokens=15, context_size=GPT_CONFIG_124M['context_length'], top_k=25, temperature=1)\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f8020523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Optimizer.load_state_dict of AdamW (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.0004\n",
       "    maximize: False\n",
       "    weight_decay: 0.1\n",
       ")>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.load_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "da2c6025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_emb.weight 38597376\n",
      "pos_emb.weight 196608\n",
      "blks.0.norm1.scale 768\n",
      "blks.0.norm1.shift 768\n",
      "blks.0.norm2.scale 768\n",
      "blks.0.norm2.shift 768\n",
      "blks.0.attn.W_q.weight 589824\n",
      "blks.0.attn.W_k.weight 589824\n",
      "blks.0.attn.W_v.weight 589824\n",
      "blks.0.attn.W_o.weight 589824\n",
      "blks.0.attn.W_o.bias 768\n",
      "blks.0.ffn.fc1.weight 2359296\n",
      "blks.0.ffn.fc1.bias 3072\n",
      "blks.0.ffn.fc2.weight 2359296\n",
      "blks.0.ffn.fc2.bias 768\n",
      "blks.1.norm1.scale 768\n",
      "blks.1.norm1.shift 768\n",
      "blks.1.norm2.scale 768\n",
      "blks.1.norm2.shift 768\n",
      "blks.1.attn.W_q.weight 589824\n",
      "blks.1.attn.W_k.weight 589824\n",
      "blks.1.attn.W_v.weight 589824\n",
      "blks.1.attn.W_o.weight 589824\n",
      "blks.1.attn.W_o.bias 768\n",
      "blks.1.ffn.fc1.weight 2359296\n",
      "blks.1.ffn.fc1.bias 3072\n",
      "blks.1.ffn.fc2.weight 2359296\n",
      "blks.1.ffn.fc2.bias 768\n",
      "blks.2.norm1.scale 768\n",
      "blks.2.norm1.shift 768\n",
      "blks.2.norm2.scale 768\n",
      "blks.2.norm2.shift 768\n",
      "blks.2.attn.W_q.weight 589824\n",
      "blks.2.attn.W_k.weight 589824\n",
      "blks.2.attn.W_v.weight 589824\n",
      "blks.2.attn.W_o.weight 589824\n",
      "blks.2.attn.W_o.bias 768\n",
      "blks.2.ffn.fc1.weight 2359296\n",
      "blks.2.ffn.fc1.bias 3072\n",
      "blks.2.ffn.fc2.weight 2359296\n",
      "blks.2.ffn.fc2.bias 768\n",
      "blks.3.norm1.scale 768\n",
      "blks.3.norm1.shift 768\n",
      "blks.3.norm2.scale 768\n",
      "blks.3.norm2.shift 768\n",
      "blks.3.attn.W_q.weight 589824\n",
      "blks.3.attn.W_k.weight 589824\n",
      "blks.3.attn.W_v.weight 589824\n",
      "blks.3.attn.W_o.weight 589824\n",
      "blks.3.attn.W_o.bias 768\n",
      "blks.3.ffn.fc1.weight 2359296\n",
      "blks.3.ffn.fc1.bias 3072\n",
      "blks.3.ffn.fc2.weight 2359296\n",
      "blks.3.ffn.fc2.bias 768\n",
      "blks.4.norm1.scale 768\n",
      "blks.4.norm1.shift 768\n",
      "blks.4.norm2.scale 768\n",
      "blks.4.norm2.shift 768\n",
      "blks.4.attn.W_q.weight 589824\n",
      "blks.4.attn.W_k.weight 589824\n",
      "blks.4.attn.W_v.weight 589824\n",
      "blks.4.attn.W_o.weight 589824\n",
      "blks.4.attn.W_o.bias 768\n",
      "blks.4.ffn.fc1.weight 2359296\n",
      "blks.4.ffn.fc1.bias 3072\n",
      "blks.4.ffn.fc2.weight 2359296\n",
      "blks.4.ffn.fc2.bias 768\n",
      "blks.5.norm1.scale 768\n",
      "blks.5.norm1.shift 768\n",
      "blks.5.norm2.scale 768\n",
      "blks.5.norm2.shift 768\n",
      "blks.5.attn.W_q.weight 589824\n",
      "blks.5.attn.W_k.weight 589824\n",
      "blks.5.attn.W_v.weight 589824\n",
      "blks.5.attn.W_o.weight 589824\n",
      "blks.5.attn.W_o.bias 768\n",
      "blks.5.ffn.fc1.weight 2359296\n",
      "blks.5.ffn.fc1.bias 3072\n",
      "blks.5.ffn.fc2.weight 2359296\n",
      "blks.5.ffn.fc2.bias 768\n",
      "blks.6.norm1.scale 768\n",
      "blks.6.norm1.shift 768\n",
      "blks.6.norm2.scale 768\n",
      "blks.6.norm2.shift 768\n",
      "blks.6.attn.W_q.weight 589824\n",
      "blks.6.attn.W_k.weight 589824\n",
      "blks.6.attn.W_v.weight 589824\n",
      "blks.6.attn.W_o.weight 589824\n",
      "blks.6.attn.W_o.bias 768\n",
      "blks.6.ffn.fc1.weight 2359296\n",
      "blks.6.ffn.fc1.bias 3072\n",
      "blks.6.ffn.fc2.weight 2359296\n",
      "blks.6.ffn.fc2.bias 768\n",
      "blks.7.norm1.scale 768\n",
      "blks.7.norm1.shift 768\n",
      "blks.7.norm2.scale 768\n",
      "blks.7.norm2.shift 768\n",
      "blks.7.attn.W_q.weight 589824\n",
      "blks.7.attn.W_k.weight 589824\n",
      "blks.7.attn.W_v.weight 589824\n",
      "blks.7.attn.W_o.weight 589824\n",
      "blks.7.attn.W_o.bias 768\n",
      "blks.7.ffn.fc1.weight 2359296\n",
      "blks.7.ffn.fc1.bias 3072\n",
      "blks.7.ffn.fc2.weight 2359296\n",
      "blks.7.ffn.fc2.bias 768\n",
      "blks.8.norm1.scale 768\n",
      "blks.8.norm1.shift 768\n",
      "blks.8.norm2.scale 768\n",
      "blks.8.norm2.shift 768\n",
      "blks.8.attn.W_q.weight 589824\n",
      "blks.8.attn.W_k.weight 589824\n",
      "blks.8.attn.W_v.weight 589824\n",
      "blks.8.attn.W_o.weight 589824\n",
      "blks.8.attn.W_o.bias 768\n",
      "blks.8.ffn.fc1.weight 2359296\n",
      "blks.8.ffn.fc1.bias 3072\n",
      "blks.8.ffn.fc2.weight 2359296\n",
      "blks.8.ffn.fc2.bias 768\n",
      "blks.9.norm1.scale 768\n",
      "blks.9.norm1.shift 768\n",
      "blks.9.norm2.scale 768\n",
      "blks.9.norm2.shift 768\n",
      "blks.9.attn.W_q.weight 589824\n",
      "blks.9.attn.W_k.weight 589824\n",
      "blks.9.attn.W_v.weight 589824\n",
      "blks.9.attn.W_o.weight 589824\n",
      "blks.9.attn.W_o.bias 768\n",
      "blks.9.ffn.fc1.weight 2359296\n",
      "blks.9.ffn.fc1.bias 3072\n",
      "blks.9.ffn.fc2.weight 2359296\n",
      "blks.9.ffn.fc2.bias 768\n",
      "blks.10.norm1.scale 768\n",
      "blks.10.norm1.shift 768\n",
      "blks.10.norm2.scale 768\n",
      "blks.10.norm2.shift 768\n",
      "blks.10.attn.W_q.weight 589824\n",
      "blks.10.attn.W_k.weight 589824\n",
      "blks.10.attn.W_v.weight 589824\n",
      "blks.10.attn.W_o.weight 589824\n",
      "blks.10.attn.W_o.bias 768\n",
      "blks.10.ffn.fc1.weight 2359296\n",
      "blks.10.ffn.fc1.bias 3072\n",
      "blks.10.ffn.fc2.weight 2359296\n",
      "blks.10.ffn.fc2.bias 768\n",
      "blks.11.norm1.scale 768\n",
      "blks.11.norm1.shift 768\n",
      "blks.11.norm2.scale 768\n",
      "blks.11.norm2.shift 768\n",
      "blks.11.attn.W_q.weight 589824\n",
      "blks.11.attn.W_k.weight 589824\n",
      "blks.11.attn.W_v.weight 589824\n",
      "blks.11.attn.W_o.weight 589824\n",
      "blks.11.attn.W_o.bias 768\n",
      "blks.11.ffn.fc1.weight 2359296\n",
      "blks.11.ffn.fc1.bias 3072\n",
      "blks.11.ffn.fc2.weight 2359296\n",
      "blks.11.ffn.fc2.bias 768\n",
      "final_norm.scale 768\n",
      "final_norm.shift 768\n",
      "out_head.weight 38597376\n",
      "out_head.bias 50257\n"
     ]
    }
   ],
   "source": [
    "for name,param in model.named_parameters():\n",
    "    print(name, param.numel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "1952d200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gpt_download.py', <http.client.HTTPMessage at 0x226d5a9c880>)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/\"\n",
    "    \"LLMs-from-scratch/main/ch05/\"\n",
    "    \"01_main-chapter-code/gpt_download.py\"\n",
    ")\n",
    "filename = url.split('/')[-1]\n",
    "urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0976fb33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\checkpoint\n",
      "File already exists and is up-to-date: gpt2\\124M\\encoder.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\hparams.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2\\124M\\vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "723a62ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
      "Params dict keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "source": [
    "print(settings)\n",
    "print(\"Params dict keys:\", params.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "95a20fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n",
      "   0.04531523]\n",
      " [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n",
      "   0.04318958]\n",
      " [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n",
      "  -0.08785918]\n",
      " ...\n",
      " [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n",
      "  -0.06952604]\n",
      " [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n",
      "  -0.02245961]\n",
      " [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n",
      "   0.12067825]]\n",
      "Token embedding weight tensor dimensions: (50257, 768)\n"
     ]
    }
   ],
   "source": [
    "print(params[\"wte\"])\n",
    "print(\"Token embedding weight tensor dimensions:\", params[\"wte\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "da890803",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "# Suppose we are interested in loading the smallest model, \"gpt2-small (124M)\". We can use the corresponding settings from the model_configs table able to update our full-length GPT_CONFIG_124M we defined and used earlier throughout the chapter as follows:\n",
    "model_name = \"gpt2-small (124M)\"\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2b45ff97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vocab_size': 50257,\n",
       " 'context_length': 256,\n",
       " 'emb_dim': 768,\n",
       " 'n_heads': 12,\n",
       " 'n_layers': 12,\n",
       " 'drop_rate': 0.1,\n",
       " 'qkv_bias': False}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NEW_CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7fe9b48c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (token_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emp): Dropout(p=0.1, inplace=False)\n",
       "  (blks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NEW_CONFIG.update({\"context_length\":1024})\n",
    "NEW_CONFIG.update({\"qkv_bias\":True})\n",
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d1df412d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9f5d6d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 5.5 Loading OpenAI weights into our GPT model code\n",
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])               #A\n",
    "    gpt.token_emb.weight = assign(gpt.token_emb.weight, params['wte'])\n",
    "    for b in range(len(params[\"blocks\"])):                                       #B\n",
    "        q_w, k_w, v_w = np.split(                                                #C\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.blks[b].attn.W_q.weight = assign(\n",
    "            gpt.blks[b].attn.W_q.weight, q_w.T)\n",
    "        gpt.blks[b].attn.W_k.weight = assign(\n",
    "            gpt.blks[b].attn.W_k.weight, k_w.T)\n",
    "        gpt.blks[b].attn.W_v.weight = assign(\n",
    "            gpt.blks[b].attn.W_v.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.blks[b].attn.W_q.bias = assign(\n",
    "            gpt.blks[b].attn.W_q.bias, q_b)\n",
    "        gpt.blks[b].attn.W_k.bias = assign(\n",
    "            gpt.blks[b].attn.W_k.bias, k_b)\n",
    "        gpt.blks[b].attn.W_v.bias = assign(\n",
    "            gpt.blks[b].attn.W_v.bias, v_b)\n",
    "\n",
    "        gpt.blks[b].attn.W_o.weight = assign(\n",
    "            gpt.blks[b].attn.W_o.weight,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.blks[b].attn.W_o.bias = assign(\n",
    "            gpt.blks[b].attn.W_o.bias,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.blks[b].ffn.fc1.weight = assign(\n",
    "            gpt.blks[b].ffn.fc1.weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.blks[b].ffn.fc1.bias = assign(\n",
    "            gpt.blks[b].ffn.fc1.bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.blks[b].ffn.fc2.weight = assign(\n",
    "            gpt.blks[b].ffn.fc2.weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.blks[b].ffn.fc2.bias = assign(\n",
    "            gpt.blks[b].ffn.fc2.bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.blks[b].norm1.scale = assign(\n",
    "            gpt.blks[b].norm1.scale,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.blks[b].norm1.shift = assign(\n",
    "            gpt.blks[b].norm1.shift,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.blks[b].norm2.scale = assign(\n",
    "            gpt.blks[b].norm2.scale,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.blks[b].norm2.shift = assign(\n",
    "            gpt.blks[b].norm2.shift,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])                   #D\n",
    "\n",
    "\n",
    "#A 将模型的位置嵌入和token 嵌入的权重设置为 params 中指定的值\n",
    "#B 遍历模型中的每个 Transformer 模块\n",
    "#C 使用 np.split 函数将注意力和偏置权重分为三等份，分别用于查询、键和值组件\n",
    "#D OpenAI 的原始 GPT-2 模型在输出层中复用了 token 嵌入的权重，以减少参数总量，这一概念称为权重共享\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4256ce7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (token_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emp): Dropout(p=0.1, inplace=False)\n",
       "  (blks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_o): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a44bb1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you as far as the hand can go until the end of your turn unless something interrupts your control flow. As you may observe I\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "token_ids = generate(model=gpt, idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device), max_new_tokens=25, context_size=NEW_CONFIG[\"context_length\"], top_k=50, temperature=1.5)\n",
    "print(f'Output text:\\n', token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "74cc5dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you was \"It his Butrow too? I haven't let by his last word.\n",
      "\n",
      "Well Rick an awful simpleton\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "token_ids = generate(model=model, idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device), max_new_tokens=25, context_size=NEW_CONFIG[\"context_length\"], top_k=50, temperature=1.5)\n",
    "print(f'Output text:\\n', token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e328d331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.22818011542161307, val loss:6.589950084686279\n"
     ]
    }
   ],
   "source": [
    "train_loss, val_loss = evaluate_mode(model, train_loader, val_loader, device, None)\n",
    "print(f'train loss:{train_loss}, val loss:{val_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5d23d14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:3.753480407926771, val loss:3.5581765174865723\n"
     ]
    }
   ],
   "source": [
    "# 看下加载了预训练权重后，在训练集和验证集上的loss情况\n",
    "train_loss, val_loss = evaluate_mode(gpt, train_loader, val_loader, device, None)\n",
    "print(f'train loss:{train_loss}, val loss:{val_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f036cfaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000)：Train loss 3.872, Val loss 3.740\n",
      "Ep 1 (Step 000001)：Train loss 3.668, Val loss 3.737\n",
      "Ep 1 (Step 000002)：Train loss 3.569, Val loss 3.660\n",
      "Ep 1 (Step 000003)：Train loss 3.394, Val loss 3.584\n",
      "Ep 1 (Step 000004)：Train loss 3.419, Val loss 3.540\n",
      "Ep 1 (Step 000005)：Train loss 3.073, Val loss 3.566\n",
      "Ep 1 (Step 000006)：Train loss 3.014, Val loss 3.546\n",
      "Ep 1 (Step 000007)：Train loss 2.873, Val loss 3.537\n",
      "Ep 1 (Step 000008)：Train loss 2.720, Val loss 3.520\n",
      "Every effort moves you forward, and you are moved by it.\"I don't know how to say that,\" he said. \"I don't know how to say that. I don't know how to say that. I don't know how to say\n"
     ]
    }
   ],
   "source": [
    "# 对加载了预训练权重的GPT训练1轮看下，相当于全量微调\n",
    "torch.manual_seed(123)\n",
    "optimizer = torch.optim.AdamW(gpt.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "num_epochs = 1\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(gpt, train_loader, val_loader, optimizer, device, num_epochs, eval_freq=1, eval_iter=5, start_context='Every effort moves you', tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e92e9a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.807166470421685, val loss:3.519531726837158\n"
     ]
    }
   ],
   "source": [
    "# 看下加载了预训练权重后，在训练集和验证集上的loss情况\n",
    "train_loss, val_loss = evaluate_mode(gpt, train_loader, val_loader, device, None)\n",
    "print(f'train loss:{train_loss}, val loss:{val_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c6938a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you under the weight of his own merits - all else if I managed to manage him like to see. It is impossible to know\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "token_ids = generate(model=gpt, idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device), max_new_tokens=25, context_size=NEW_CONFIG[\"context_length\"], top_k=50, temperature=1.5)\n",
    "print(f'Output text:\\n', token_ids_to_text(token_ids, tokenizer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
