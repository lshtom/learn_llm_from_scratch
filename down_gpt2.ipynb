{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58cf96b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\checkpoint\n",
      "File already exists and is up-to-date: gpt2\\124M\\encoder.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\hparams.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2\\124M\\vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "021c85cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n"
     ]
    }
   ],
   "source": [
    "print(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62f7e12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params dict keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Params dict keys:\", params.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c082a2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt_download import load_gpt2_params_from_tf_ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c8505d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "DataLossError",
     "evalue": "Unable to open table file E:\\Project\\Learn\\learn_llm_from_scratch\\gpt2\\124M\\model.ckpt.data-00000-of-00001: DATA_LOSS: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32md:\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\py_checkpoint_reader.py:92\u001b[0m, in \u001b[0;36mNewCheckpointReader\u001b[1;34m(filepattern)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 92\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mCheckpointReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepattern\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# TODO(b/143319754): Remove the RuntimeError casting logic once we resolve the\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;66;03m# issue with throwing python exceptions from C++.\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Unable to open table file E:\\Project\\Learn\\learn_llm_from_scratch\\gpt2\\124M\\model.ckpt.data-00000-of-00001: DATA_LOSS: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator?",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mDataLossError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m new_params \u001b[38;5;241m=\u001b[39m \u001b[43mload_gpt2_params_from_tf_ckpt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mE:\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mProject\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mLearn\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mlearn_llm_from_scratch\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mgpt2\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43m124M\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mmodel.ckpt.data-00000-of-00001\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msettings\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\Project\\Learn\\learn_llm_from_scratch\\gpt_download.py:131\u001b[0m, in \u001b[0;36mload_gpt2_params_from_tf_ckpt\u001b[1;34m(ckpt_path, settings)\u001b[0m\n\u001b[0;32m    128\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblocks\u001b[39m\u001b[38;5;124m\"\u001b[39m: [{} \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_layer\u001b[39m\u001b[38;5;124m\"\u001b[39m])]}\n\u001b[0;32m    130\u001b[0m \u001b[38;5;66;03m# Iterate over each variable in the checkpoint\u001b[39;00m\n\u001b[1;32m--> 131\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, _ \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;66;03m# Load the variable and remove singleton dimensions\u001b[39;00m\n\u001b[0;32m    133\u001b[0m     variable_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqueeze(tf\u001b[38;5;241m.\u001b[39mtrain\u001b[38;5;241m.\u001b[39mload_variable(ckpt_path, name))\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;66;03m# Process the variable name to extract relevant parts\u001b[39;00m\n",
      "File \u001b[1;32md:\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\checkpoint_utils.py:115\u001b[0m, in \u001b[0;36mlist_variables\u001b[1;34m(ckpt_dir_or_file)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain.list_variables\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlist_variables\u001b[39m(ckpt_dir_or_file):\n\u001b[0;32m     93\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Lists the checkpoint keys and shapes of variables in a checkpoint.\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \n\u001b[0;32m     95\u001b[0m \u001b[38;5;124;03m  Checkpoint keys are paths in a checkpoint graph.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;124;03m    List of tuples `(key, shape)`.\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 115\u001b[0m   reader \u001b[38;5;241m=\u001b[39m \u001b[43mload_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckpt_dir_or_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    116\u001b[0m   variable_map \u001b[38;5;241m=\u001b[39m reader\u001b[38;5;241m.\u001b[39mget_variable_to_shape_map()\n\u001b[0;32m    117\u001b[0m   names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(variable_map\u001b[38;5;241m.\u001b[39mkeys())\n",
      "File \u001b[1;32md:\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\checkpoint_utils.py:70\u001b[0m, in \u001b[0;36mload_checkpoint\u001b[1;34m(ckpt_dir_or_file)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     68\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheckpoint\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m file or checkpoints in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     69\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgiven directory \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m ckpt_dir_or_file)\n\u001b[1;32m---> 70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpy_checkpoint_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNewCheckpointReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\py_checkpoint_reader.py:96\u001b[0m, in \u001b[0;36mNewCheckpointReader\u001b[1;34m(filepattern)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# TODO(b/143319754): Remove the RuntimeError casting logic once we resolve the\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;66;03m# issue with throwing python exceptions from C++.\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 96\u001b[0m   \u001b[43merror_translator\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\py_checkpoint_reader.py:40\u001b[0m, in \u001b[0;36merror_translator\u001b[1;34m(e)\u001b[0m\n\u001b[0;32m     38\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m errors_impl\u001b[38;5;241m.\u001b[39mInvalidArgumentError(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, error_message)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnable to open table file\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error_message:\n\u001b[1;32m---> 40\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m errors_impl\u001b[38;5;241m.\u001b[39mDataLossError(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, error_message)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFailed to find the saved tensor slices\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error_message \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnot convertible to numpy dtype\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error_message):\n\u001b[0;32m     43\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m errors_impl\u001b[38;5;241m.\u001b[39mInternalError(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, error_message)\n",
      "\u001b[1;31mDataLossError\u001b[0m: Unable to open table file E:\\Project\\Learn\\learn_llm_from_scratch\\gpt2\\124M\\model.ckpt.data-00000-of-00001: DATA_LOSS: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator?"
     ]
    }
   ],
   "source": [
    "new_params = load_gpt2_params_from_tf_ckpt('E:\\\\Project\\\\Learn\\\\learn_llm_from_scratch\\\\gpt2\\\\124M\\\\model.ckpt.data-00000-of-00001', settings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
